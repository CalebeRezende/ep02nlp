# ep02nlp

# EP02: Projeto de Regressão e Quantização de Transformadores

## Visão geral
Este projeto envolve uma exploração da arquitetura Transformers, do tipo BERT.Faremos em todo esse projeto, uma regressão numérica para densidade de vogais. A densidade calculada aqui foi da seguinte forma: 

A= todas as vogais
B= todo o alfabeto

C= A/B
Com essa ideia, exploramos formas de melhorar tal regressão. 
Será dividido em 3 tarefas, e depois comparaamos entre elas qual foi a melhoria. 


# Requisitos
Para usar este (.ipynb), foi necessário usar A100 do Colab, para carregar, sem o mesmo há a desconexão por inatividade.

Para rodar todos os cálculos, pode ser feito via: execute.tudo, não há qualquer coisa que precise ser indexado. 

No mais, desfrute lendo o artigo desenvolvido a partir desse git
